{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "from pudb import set_trace;\n",
    "\n",
    "with open('data/countries_s1_dbg') as f:\n",
    "    facts = f.read().splitlines()\n",
    "facts = [el.split(',') for el in facts]\n",
    "preds = [fact[0] for fact in facts]\n",
    "subjs = [fact[1] for fact in facts]\n",
    "objs = [fact[2] for fact in facts]\n",
    "\n",
    "unique = sorted(list(set(preds)))\n",
    "num_unique = len(unique)\n",
    "num_predicates = num_unique\n",
    "predsToIdx = dict(zip(unique,range(num_unique)))\n",
    "idxToPreds = dict(zip(range(num_unique),unique))\n",
    "\n",
    "unique = sorted(list(set(subjs+objs)))\n",
    "num_unique = len(unique)\n",
    "num_constants = num_unique\n",
    "consToIdx = dict(zip(unique,range(num_unique)))\n",
    "idxToCons = dict(zip(range(num_unique),unique))\n",
    "\n",
    "facts = np.array([(predsToIdx[preds[i]],consToIdx[subjs[i]], consToIdx[objs[i]]) for i in range(len(facts))])\n",
    "data = np.zeros((num_predicates,num_constants,num_constants))\n",
    "\n",
    "#data: idx0->predicate, idx1->subj, idx2->obj\n",
    "data[facts[:,0],facts[:,1],facts[:,2]] = 1\n",
    "no_facts = int(np.sum(data))\n",
    "data = torch.from_numpy(data)\n",
    "\n",
    "predicates = torch.eye(num_predicates)\n",
    "constants = torch.eye(num_constants)\n",
    "\n",
    "knowledge_pos = (data==1).nonzero()\n",
    "data_aux = knowledge_pos\n",
    "knowledge_pos = torch.cat((predicates[knowledge_pos[:,0]],\n",
    "                           constants[knowledge_pos[:,1]],\n",
    "                           constants[knowledge_pos[:,2]]),dim=1)\n",
    "num_facts = knowledge_pos.size()[0]\n",
    "num_feats_per_fact = knowledge_pos.size()[1]\n",
    "print(num_facts,num_feats_per_fact)\n",
    "\n",
    "#helps removing repeated predicted facts -> same embeddings and constants, probably different scores\n",
    "#this is of complexity K^3, could be optimized\n",
    "def leaveTopK(preds,K):\n",
    "    _,idx = torch.sort(preds[:,-1],descending=True)\n",
    "    preds = preds[idx,:]\n",
    "    out = preds[0,:].unsqueeze(0)\n",
    "    for i in range(1,K):\n",
    "        t = preds[i,:].unsqueeze(0)\n",
    "        m,_ = torch.max(F.cosine_similarity(t[:,:-1].repeat(out.size()[0],1),out[:,:-1]),dim=0)\n",
    "        if m<1:\n",
    "            out = torch.cat((out,t),dim=0)\n",
    "    return out\n",
    "\n",
    "####FORWARD CHAINING\n",
    "#input: some facts that can either be ground or predicted in previous steps\n",
    "#output: predicted facts in this specific step (outer loop must gather all of them)\n",
    "#computes the predictions of applying each rule to the facts, giving a score to each of them.\n",
    "#leaves only topK scoring fact for each applied rule (not for the whole thing)\n",
    "def forward_step(facts):\n",
    "    #rule 1\n",
    "    # b1(x,y)<-b1(y,x)\n",
    "    rule_expanded = rules[0].expand(facts[:,:num_predicates].size())\n",
    "    preds_r1 = F.cosine_similarity(rule_expanded,facts[:,:num_predicates],dim=1)\n",
    "    preds_r1 = preds_r1*facts[:,-1]\n",
    "    preds_r1 = preds_r1.unsqueeze(1)\n",
    "    preds_r1 = torch.cat((rule_expanded,\n",
    "                         facts[:,num_predicates+num_constants:-1],\n",
    "                         facts[:,num_predicates:num_predicates+num_constants],\n",
    "                         preds_r1),dim=1)\n",
    "    preds_r1 = leaveTopK(preds_r1,K)\n",
    "    #rule 2\n",
    "    # b1(x,y)<-b2(x,z),b2(z,y)\n",
    "    body1 = facts.repeat((1,num_facts)).view(-1,num_feats_per_fact+1)\n",
    "    body2 = facts.repeat((num_facts,1))\n",
    "    rule_expanded = rules[1].repeat(body1.size()[0],1)\n",
    "    #previous scores\n",
    "    preds_r2 = body1[:,-1]*body2[:,-1]\n",
    "    #predicate of body1 with predicate of rule\n",
    "    preds_r2 = preds_r2*F.cosine_similarity(rule_expanded[:,num_predicates:],body1[:,:num_predicates],dim=1)\n",
    "    #predicate of body2 with predicate of rule\n",
    "    preds_r2 = preds_r2*F.cosine_similarity(rule_expanded[:,num_predicates:],body2[:,:num_predicates],dim=1)\n",
    "    #similarity between shared constants\n",
    "    preds_r2 = preds_r2*F.cosine_similarity(body1[:,num_predicates+num_constants:-1],\n",
    "                                            body2[:,num_predicates:num_predicates+num_constants],dim=1)\n",
    "    preds_r2 = preds_r2.unsqueeze(1)\n",
    "    preds_r2 = torch.cat((rule_expanded[:,:num_predicates]\n",
    "                         ,body1[:,num_predicates:num_predicates+num_constants]\n",
    "                         ,body2[:,num_predicates+num_constants:-1]\n",
    "                         ,preds_r2)\n",
    "                        ,dim=1)\n",
    "    #removing repeated facts and leaving ones with highest score\n",
    "    preds_r2 = leaveTopK(preds_r2,K)\n",
    "    out = torch.cat((preds_r1,preds_r2),dim=0)\n",
    "    return out\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aldo.pareja/miniconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/aldo.pareja/miniconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 losssssssssssssssssssss tensor(8.0640)\n",
      "[tensor([ 0.5830,  0.6683]), tensor([ 0.2406,  0.0174,  0.4055,  0.1823])]\n",
      "1 losssssssssssssssssssss tensor(8.0082)\n",
      "[tensor([ 0.5730,  0.6583]), tensor([ 0.2506,  0.0074,  0.4155,  0.1723])]\n",
      "2 losssssssssssssssssssss tensor(7.9562)\n",
      "[tensor([ 0.5631,  0.6483]), tensor([ 0.2606, -0.0017,  0.4254,  0.1623])]\n",
      "3 losssssssssssssssssssss tensor(7.9079)\n",
      "[tensor([ 0.5534,  0.6384]), tensor([ 0.2706, -0.0081,  0.4353,  0.1523])]\n",
      "4 losssssssssssssssssssss tensor(7.8632)\n",
      "[tensor([ 0.5440,  0.6284]), tensor([ 0.2806, -0.0107,  0.4450,  0.1424])]\n",
      "5 losssssssssssssssssssss tensor(7.8220)\n",
      "[tensor([ 0.5350,  0.6186]), tensor([ 0.2905, -0.0100,  0.4545,  0.1326])]\n",
      "6 losssssssssssssssssssss tensor(7.7841)\n",
      "[tensor([ 0.5268,  0.6088]), tensor([ 0.3005, -0.0075,  0.4637,  0.1229])]\n",
      "7 losssssssssssssssssssss tensor(7.7494)\n",
      "[tensor([ 0.5195,  0.5991]), tensor([ 0.3104, -0.0039,  0.4726,  0.1133])]\n",
      "8 losssssssssssssssssssss tensor(7.7175)\n",
      "[tensor([ 0.5132,  0.5896]), tensor([ 0.3204, -0.0001,  0.4813,  0.1038])]\n",
      "9 losssssssssssssssssssss tensor(7.6882)\n",
      "[tensor([ 0.5082,  0.5801]), tensor([ 0.3303,  0.0034,  0.4895,  0.0945])]\n",
      "10 losssssssssssssssssssss tensor(7.6612)\n",
      "[tensor([ 0.5045,  0.5709]), tensor([ 0.3401,  0.0058,  0.4973,  0.0854])]\n",
      "11 losssssssssssssssssssss tensor(7.6364)\n",
      "[tensor([ 0.5020,  0.5618]), tensor([ 0.3500,  0.0069,  0.5047,  0.0765])]\n",
      "12 losssssssssssssssssssss tensor(7.6135)\n",
      "[tensor([ 0.5006,  0.5529]), tensor([ 0.3598,  0.0067,  0.5117,  0.0679])]\n",
      "13 losssssssssssssssssssss tensor(7.5925)\n",
      "[tensor([ 0.5002,  0.5443]), tensor([ 0.3696,  0.0054,  0.5182,  0.0596])]\n",
      "14 losssssssssssssssssssss tensor(6.6539)\n",
      "[tensor([ 0.5004,  0.5361]), tensor([ 0.3793,  0.0033,  0.5243,  0.0516])]\n",
      "15 losssssssssssssssssssss tensor(6.6010)\n",
      "[tensor([ 0.4958,  0.5333]), tensor([ 0.3893,  0.0000,  0.5301,  0.0432])]\n",
      "16 losssssssssssssssssssss tensor(6.5334)\n",
      "[tensor([ 0.4893,  0.5338]), tensor([ 0.3996, -0.0030,  0.5357,  0.0348])]\n",
      "17 losssssssssssssssssssss tensor(6.4566)\n",
      "[tensor([ 0.4817,  0.5365]), tensor([ 0.4102, -0.0043,  0.5409,  0.0264])]\n",
      "18 losssssssssssssssssssss tensor(6.3739)\n",
      "[tensor([ 0.4733,  0.5408]), tensor([ 0.4210, -0.0035,  0.5458,  0.0182])]\n",
      "19 losssssssssssssssssssss tensor(6.2876)\n",
      "[tensor([ 0.4642,  0.5464]), tensor([ 0.4319, -0.0014,  0.5503,  0.0103])]\n",
      "20 losssssssssssssssssssss tensor(6.1991)\n",
      "[tensor([ 0.4546,  0.5529]), tensor([ 0.4430,  0.0011,  0.5543,  0.0029])]\n",
      "21 losssssssssssssssssssss tensor(6.1096)\n",
      "[tensor([ 0.4446,  0.5601]), tensor([ 0.4542,  0.0029,  0.5580, -0.0039])]\n",
      "22 losssssssssssssssssssss tensor(6.0198)\n",
      "[tensor([ 0.4342,  0.5680]), tensor([ 0.4654,  0.0033,  0.5614, -0.0100])]\n",
      "23 losssssssssssssssssssss tensor(5.9302)\n",
      "[tensor([ 0.4237,  0.5764]), tensor([ 0.4767,  0.0023,  0.5645, -0.0153])]\n",
      "24 losssssssssssssssssssss tensor(5.8413)\n",
      "[tensor([ 0.4129,  0.5851]), tensor([ 0.4880,  0.0005,  0.5673, -0.0197])]\n",
      "25 losssssssssssssssssssss tensor(5.7533)\n",
      "[tensor([ 0.4020,  0.5941]), tensor([ 0.4993, -0.0013,  0.5700, -0.0233])]\n",
      "26 losssssssssssssssssssss tensor(5.6667)\n",
      "[tensor([ 0.3910,  0.6034]), tensor([ 0.5106, -0.0025,  0.5724, -0.0260])]\n",
      "27 losssssssssssssssssssss tensor(5.5816)\n",
      "[tensor([ 0.3799,  0.6128]), tensor([ 0.5218, -0.0025,  0.5748, -0.0279])]\n",
      "28 losssssssssssssssssssss tensor(5.4983)\n",
      "[tensor([ 0.3688,  0.6224]), tensor([ 0.5330, -0.0015,  0.5770, -0.0289])]\n",
      "29 losssssssssssssssssssss tensor(5.4170)\n",
      "[tensor([ 0.3576,  0.6320]), tensor([ 0.5441,  0.0000,  0.5792, -0.0291])]\n",
      "30 losssssssssssssssssssss tensor(5.3380)\n",
      "[tensor([ 0.3465,  0.6417]), tensor([ 0.5552,  0.0014,  0.5813, -0.0286])]\n",
      "31 losssssssssssssssssssss tensor(5.2614)\n",
      "[tensor([ 0.3354,  0.6513]), tensor([ 0.5662,  0.0020,  0.5832, -0.0275])]\n",
      "32 losssssssssssssssssssss tensor(5.1874)\n",
      "[tensor([ 0.3244,  0.6610]), tensor([ 0.5771,  0.0018,  0.5852, -0.0259])]\n",
      "33 losssssssssssssssssssss tensor(5.1163)\n",
      "[tensor([ 0.3135,  0.6706]), tensor([ 0.5878,  0.0008,  0.5870, -0.0238])]\n",
      "34 losssssssssssssssssssss tensor(5.0480)\n",
      "[tensor([ 0.3026,  0.6801]), tensor([ 0.5985, -0.0004,  0.5888, -0.0214])]\n",
      "35 losssssssssssssssssssss tensor(4.9828)\n",
      "[tensor([ 0.2919,  0.6895]), tensor([ 0.6091, -0.0014,  0.5904, -0.0187])]\n",
      "36 losssssssssssssssssssss tensor(4.9206)\n",
      "[tensor([ 0.2812,  0.6988]), tensor([ 0.6195, -0.0016,  0.5920, -0.0158])]\n",
      "37 losssssssssssssssssssss tensor(4.8615)\n",
      "[tensor([ 0.2708,  0.7080]), tensor([ 0.6299, -0.0012,  0.5934, -0.0128])]\n",
      "38 losssssssssssssssssssss tensor(4.8054)\n",
      "[tensor([ 0.2604,  0.7170]), tensor([ 0.6401, -0.0002,  0.5948, -0.0097])]\n",
      "39 losssssssssssssssssssss tensor(4.7523)\n",
      "[tensor([ 0.2503,  0.7259]), tensor([ 0.6501,  0.0007,  0.5960, -0.0067])]\n",
      "40 losssssssssssssssssssss tensor(4.7022)\n",
      "[tensor([ 0.2403,  0.7347]), tensor([ 0.6600,  0.0013,  0.5971, -0.0039])]\n",
      "41 losssssssssssssssssssss tensor(4.6549)\n",
      "[tensor([ 0.2304,  0.7432]), tensor([ 0.6698,  0.0012,  0.5981, -0.0011])]\n",
      "42 losssssssssssssssssssss tensor(4.6104)\n",
      "[tensor([ 0.2208,  0.7516]), tensor([ 0.6794,  0.0006,  0.5991,  0.0014])]\n",
      "43 losssssssssssssssssssss tensor(4.5684)\n",
      "[tensor([ 0.2114,  0.7598]), tensor([ 0.6889, -0.0002,  0.5999,  0.0036])]\n",
      "44 losssssssssssssssssssss tensor(4.5290)\n",
      "[tensor([ 0.2022,  0.7678]), tensor([ 0.6982, -0.0009,  0.6007,  0.0056])]\n",
      "45 losssssssssssssssssssss tensor(4.4919)\n",
      "[tensor([ 0.1932,  0.7756]), tensor([ 0.7074, -0.0010,  0.6014,  0.0072])]\n",
      "46 losssssssssssssssssssss tensor(4.4570)\n",
      "[tensor([ 0.1844,  0.7832]), tensor([ 0.7164, -0.0007,  0.6021,  0.0085])]\n",
      "47 losssssssssssssssssssss tensor(4.4243)\n",
      "[tensor([ 0.1758,  0.7907]), tensor([ 0.7253, -0.0001,  0.6027,  0.0095])]\n",
      "48 losssssssssssssssssssss tensor(4.3936)\n",
      "[tensor([ 0.1675,  0.7979]), tensor([ 0.7340,  0.0005,  0.6033,  0.0101])]\n",
      "49 losssssssssssssssssssss tensor(4.3647)\n",
      "[tensor([ 0.1594,  0.8050]), tensor([ 0.7425,  0.0008,  0.6038,  0.0104])]\n",
      "50 losssssssssssssssssssss tensor(4.3377)\n",
      "[tensor([ 0.1515,  0.8118]), tensor([ 0.7509,  0.0007,  0.6043,  0.0105])]\n",
      "51 losssssssssssssssssssss tensor(4.3124)\n",
      "[tensor([ 0.1439,  0.8185]), tensor([ 0.7591,  0.0002,  0.6047,  0.0102])]\n",
      "52 losssssssssssssssssssss tensor(4.2887)\n",
      "[tensor([ 0.1364,  0.8250]), tensor([ 0.7672, -0.0003,  0.6052,  0.0097])]\n",
      "53 losssssssssssssssssssss tensor(4.2666)\n",
      "[tensor([ 0.1293,  0.8312]), tensor([ 0.7751, -0.0006,  0.6056,  0.0090])]\n",
      "54 losssssssssssssssssssss tensor(4.2459)\n",
      "[tensor([ 0.1223,  0.8374]), tensor([ 0.7828, -0.0006,  0.6060,  0.0081])]\n",
      "55 losssssssssssssssssssss tensor(4.2267)\n",
      "[tensor([ 0.1156,  0.8433]), tensor([ 0.7903, -0.0003,  0.6063,  0.0071])]\n",
      "56 losssssssssssssssssssss tensor(4.2088)\n",
      "[tensor([ 0.1092,  0.8490]), tensor([ 0.7977,  0.0002,  0.6067,  0.0060])]\n",
      "57 losssssssssssssssssssss tensor(4.1921)\n",
      "[tensor([ 0.1029,  0.8546]), tensor([ 0.8050,  0.0005,  0.6070,  0.0048])]\n",
      "58 losssssssssssssssssssss tensor(4.1767)\n",
      "[tensor([ 0.0969,  0.8600]), tensor([ 0.8120,  0.0005,  0.6073,  0.0036])]\n",
      "59 losssssssssssssssssssss tensor(4.1623)\n",
      "[tensor([ 0.0911,  0.8652]), tensor([ 0.8189,  0.0003,  0.6075,  0.0024])]\n",
      "60 losssssssssssssssssssss tensor(4.1491)\n",
      "[tensor([ 0.0856,  0.8703]), tensor([ 0.8257, -0.0001,  0.6078,  0.0013])]\n",
      "61 losssssssssssssssssssss tensor(4.1368)\n",
      "[tensor([ 0.0803,  0.8752]), tensor([ 0.8322, -0.0004,  0.6080,  0.0002])]\n",
      "62 losssssssssssssssssssss tensor(4.1255)\n",
      "[tensor([ 0.0752,  0.8800]), tensor([ 0.8386, -0.0004,  0.6082, -0.0008])]\n",
      "63 losssssssssssssssssssss tensor(4.1150)\n",
      "[tensor([ 0.0703,  0.8846]), tensor([ 0.8449, -0.0002,  0.6084, -0.0017])]\n",
      "64 losssssssssssssssssssss tensor(4.1053)\n",
      "[tensor([ 0.0656,  0.8890]), tensor([ 0.8510,  0.0001,  0.6085, -0.0024])]\n",
      "65 losssssssssssssssssssss tensor(4.0964)\n",
      "[tensor([ 0.0611,  0.8934]), tensor([ 0.8569,  0.0003,  0.6087, -0.0030])]\n",
      "66 losssssssssssssssssssss tensor(4.0881)\n",
      "[tensor([ 0.0568,  0.8975]), tensor([ 0.8627,  0.0004,  0.6088, -0.0035])]\n",
      "67 losssssssssssssssssssss tensor(4.0805)\n",
      "[tensor([ 0.0528,  0.9016]), tensor([ 0.8683,  0.0002,  0.6089, -0.0038])]\n",
      "68 losssssssssssssssssssss tensor(4.0735)\n",
      "[tensor([ 0.0489,  0.9055]), tensor([ 0.8737, -0.0000,  0.6091, -0.0040])]\n",
      "69 losssssssssssssssssssss tensor(4.0670)\n",
      "[tensor([ 0.0452,  0.9093]), tensor([ 0.8790, -0.0003,  0.6092, -0.0040])]\n",
      "70 losssssssssssssssssssss tensor(4.0611)\n",
      "[tensor([ 0.0417,  0.9129]), tensor([ 0.8842, -0.0003,  0.6093, -0.0039])]\n",
      "71 losssssssssssssssssssss tensor(4.0556)\n",
      "[tensor([ 0.0384,  0.9164]), tensor([ 0.8892, -0.0002,  0.6094, -0.0037])]\n",
      "72 losssssssssssssssssssss tensor(4.0506)\n",
      "[tensor([ 0.0352,  0.9198]), tensor([ 0.8940,  0.0001,  0.6094, -0.0034])]\n",
      "73 losssssssssssssssssssss tensor(4.0460)\n",
      "[tensor([ 0.0322,  0.9231]), tensor([ 0.8987,  0.0002,  0.6095, -0.0031])]\n",
      "74 losssssssssssssssssssss tensor(4.0417)\n",
      "[tensor([ 0.0294,  0.9263]), tensor([ 0.9033,  0.0002,  0.6096, -0.0026])]\n",
      "75 losssssssssssssssssssss tensor(4.0378)\n",
      "[tensor([ 0.0268,  0.9294]), tensor([ 0.9077,  0.0001,  0.6097, -0.0022])]\n",
      "76 losssssssssssssssssssss tensor(4.0343)\n",
      "[tensor([ 0.0242,  0.9323]), tensor([ 0.9120, -0.0001,  0.6097, -0.0017])]\n",
      "77 losssssssssssssssssssss tensor(4.0310)\n",
      "[tensor([ 0.0219,  0.9352]), tensor([ 0.9161, -0.0002,  0.6098, -0.0012])]\n",
      "78 losssssssssssssssssssss tensor(4.0281)\n",
      "[tensor([ 0.0197,  0.9380]), tensor([ 0.9201, -0.0002,  0.6098, -0.0007])]\n",
      "79 losssssssssssssssssssss tensor(4.0254)\n",
      "[tensor([ 0.0176,  0.9406]), tensor([ 0.9240, -0.0001,  0.6099, -0.0002])]\n",
      "80 losssssssssssssssssssss tensor(4.0229)\n",
      "[tensor([ 0.0156,  0.9432]), tensor([ 0.9277,  0.0001,  0.6099,  0.0002])]\n",
      "81 losssssssssssssssssssss tensor(4.0207)\n",
      "[tensor([ 0.0138,  0.9457]), tensor([ 0.9313,  0.0002,  0.6100,  0.0006])]\n",
      "82 losssssssssssssssssssss tensor(4.0186)\n",
      "[tensor([ 0.0121,  0.9481]), tensor([ 0.9348,  0.0001,  0.6100,  0.0009])]\n",
      "83 losssssssssssssssssssss tensor(4.0168)\n",
      "[tensor([ 0.0105,  0.9504]), tensor([ 0.9381,  0.0000,  0.6100,  0.0012])]\n",
      "84 losssssssssssssssssssss tensor(4.0151)\n",
      "[tensor([ 0.0090,  0.9526]), tensor([ 0.9413, -0.0001,  0.6101,  0.0014])]\n",
      "85 losssssssssssssssssssss tensor(4.0136)\n",
      "[tensor([ 0.0076,  0.9548]), tensor([ 0.9444, -0.0001,  0.6101,  0.0015])]\n",
      "86 losssssssssssssssssssss tensor(4.0122)\n",
      "[tensor([ 0.0063,  0.9568]), tensor([ 0.9474, -0.0001,  0.6101,  0.0016])]\n",
      "87 losssssssssssssssssssss tensor(4.0109)\n",
      "[tensor([ 0.0052,  0.9588]), tensor([ 9.5027e-01,  1.0553e-06,  6.1015e-01,  1.6050e-03])]\n",
      "88 losssssssssssssssssssss tensor(4.0098)\n",
      "[tensor([ 0.0041,  0.9607]), tensor([ 0.9530,  0.0001,  0.6102,  0.0016])]\n",
      "89 losssssssssssssssssssss tensor(4.0087)\n",
      "[tensor([ 0.0031,  0.9626]), tensor([ 0.9557,  0.0001,  0.6102,  0.0015])]\n",
      "90 losssssssssssssssssssss tensor(4.0078)\n",
      "[tensor([ 0.0021,  0.9643]), tensor([ 0.9582,  0.0001,  0.6102,  0.0013])]\n",
      "91 losssssssssssssssssssss tensor(4.0070)\n",
      "[tensor([ 0.0013,  0.9660]), tensor([ 0.9606, -0.0000,  0.6102,  0.0012])]\n",
      "92 losssssssssssssssssssss tensor(4.0062)\n",
      "[tensor([ 0.0005,  0.9677]), tensor([ 0.9630, -0.0001,  0.6102,  0.0010])]\n",
      "93 losssssssssssssssssssss tensor(4.0055)\n",
      "[tensor([-0.0002,  0.9693]), tensor([ 0.9652, -0.0001,  0.6103,  0.0008])]\n",
      "94 losssssssssssssssssssss tensor(4.0049)\n",
      "[tensor([-0.0008,  0.9708]), tensor([ 0.9673, -0.0000,  0.6103,  0.0006])]\n",
      "95 losssssssssssssssssssss tensor(4.0044)\n",
      "[tensor([-0.0013,  0.9722]), tensor([ 0.9694,  0.0000,  0.6103,  0.0003])]\n",
      "96 losssssssssssssssssssss tensor(4.0039)\n",
      "[tensor([-0.0019,  0.9736]), tensor([ 0.9713,  0.0001,  0.6103,  0.0001])]\n",
      "97 losssssssssssssssssssss tensor(4.0034)\n",
      "[tensor([-0.0023,  0.9750]), tensor([ 0.9732,  0.0001,  0.6103, -0.0001])]\n",
      "98 losssssssssssssssssssss tensor(4.0030)\n",
      "[tensor([-0.0027,  0.9763]), tensor([ 9.7497e-01, -3.6987e-06,  6.1031e-01, -2.2232e-04])]\n",
      "99 losssssssssssssssssssss tensor(4.0027)\n",
      "[tensor([-0.0030,  0.9775]), tensor([ 0.9767, -0.0001,  0.6103, -0.0004])]\n",
      "100 losssssssssssssssssssss tensor(4.0024)\n",
      "[tensor([-0.0034,  0.9787]), tensor([ 0.9783, -0.0001,  0.6103, -0.0005])]\n",
      "101 losssssssssssssssssssss tensor(4.0021)\n",
      "[tensor([-0.0036,  0.9798]), tensor([ 0.9798, -0.0000,  0.6103, -0.0006])]\n",
      "102 losssssssssssssssssssss tensor(4.0018)\n",
      "[tensor([-0.0038,  0.9809]), tensor([ 0.9812,  0.0000,  0.6103, -0.0006])]\n",
      "103 losssssssssssssssssssss tensor(4.0016)\n",
      "[tensor([-0.0040,  0.9819]), tensor([ 0.9826,  0.0001,  0.6103, -0.0007])]\n",
      "104 losssssssssssssssssssss tensor(4.0014)\n",
      "[tensor([-0.0042,  0.9829]), tensor([ 0.9839,  0.0000,  0.6104, -0.0007])]\n",
      "105 losssssssssssssssssssss tensor(4.0012)\n",
      "[tensor([-0.0043,  0.9839]), tensor([ 9.8518e-01,  2.3554e-06,  6.1036e-01, -6.5239e-04])]\n",
      "106 losssssssssssssssssssss tensor(4.0011)\n",
      "[tensor([-0.0044,  0.9848]), tensor([ 0.9864, -0.0000,  0.6104, -0.0006])]\n",
      "107 losssssssssssssssssssss tensor(4.0009)\n",
      "[tensor([-0.0044,  0.9857]), tensor([ 0.9875, -0.0000,  0.6104, -0.0005])]\n",
      "108 losssssssssssssssssssss tensor(4.0008)\n",
      "[tensor([-0.0045,  0.9865]), tensor([ 0.9885, -0.0000,  0.6104, -0.0005])]\n",
      "109 losssssssssssssssssssss tensor(4.0007)\n",
      "[tensor([-0.0045,  0.9873]), tensor([ 0.9895,  0.0000,  0.6104, -0.0004])]\n",
      "110 losssssssssssssssssssss tensor(4.0006)\n",
      "[tensor([-0.0045,  0.9881]), tensor([ 0.9904,  0.0000,  0.6104, -0.0003])]\n",
      "111 losssssssssssssssssssss tensor(4.0005)\n",
      "[tensor([-0.0045,  0.9888]), tensor([ 0.9913,  0.0000,  0.6104, -0.0002])]\n",
      "112 losssssssssssssssssssss tensor(4.0005)\n",
      "[tensor([-0.0044,  0.9895]), tensor([ 9.9214e-01,  1.0213e-06,  6.1038e-01, -1.0100e-04])]\n",
      "113 losssssssssssssssssssss tensor(4.0004)\n",
      "[tensor([-0.0044,  0.9901]), tensor([ 0.9929, -0.0000,  0.6104, -0.0000])]\n",
      "114 losssssssssssssssssssss tensor(4.0003)\n",
      "[tensor([-0.0043,  0.9908]), tensor([ 0.9936, -0.0000,  0.6104,  0.0001])]\n",
      "115 losssssssssssssssssssss tensor(4.0003)\n",
      "[tensor([-0.0042,  0.9913]), tensor([ 0.9943, -0.0000,  0.6104,  0.0001])]\n",
      "116 losssssssssssssssssssss tensor(4.0003)\n",
      "[tensor([-0.0041,  0.9919]), tensor([ 0.9950,  0.0000,  0.6104,  0.0002])]\n",
      "117 losssssssssssssssssssss tensor(4.0002)\n",
      "[tensor([-0.0040,  0.9924]), tensor([ 0.9956,  0.0000,  0.6104,  0.0002])]\n",
      "118 losssssssssssssssssssss tensor(4.0002)\n",
      "[tensor([-0.0039,  0.9930]), tensor([ 0.9961,  0.0000,  0.6104,  0.0003])]\n",
      "119 losssssssssssssssssssss tensor(4.0002)\n",
      "[tensor([-0.0038,  0.9934]), tensor([ 9.9662e-01, -2.4586e-06,  6.1039e-01,  2.8946e-04])]\n",
      "120 losssssssssssssssssssss tensor(4.0001)\n",
      "[tensor([-0.0037,  0.9939]), tensor([ 0.9971, -0.0000,  0.6104,  0.0003])]\n",
      "121 losssssssssssssssssssss tensor(4.0001)\n",
      "[tensor([-0.0035,  0.9943]), tensor([ 0.9975, -0.0000,  0.6104,  0.0003])]\n",
      "122 losssssssssssssssssssss tensor(4.0001)\n",
      "[tensor([-0.0034,  0.9948]), tensor([ 9.9795e-01, -5.3168e-06,  6.1040e-01,  2.6728e-04])]\n",
      "123 losssssssssssssssssssss tensor(4.0001)\n",
      "[tensor([-0.0033,  0.9951]), tensor([ 0.9983,  0.0000,  0.6104,  0.0002])]\n",
      "124 losssssssssssssssssssss tensor(4.0001)\n",
      "[tensor([-0.0031,  0.9955]), tensor([ 0.9987,  0.0000,  0.6104,  0.0002])]\n",
      "125 losssssssssssssssssssss tensor(4.0001)\n",
      "[tensor([-0.0030,  0.9959]), tensor([ 0.9990,  0.0000,  0.6104,  0.0002])]\n",
      "126 losssssssssssssssssssss tensor(4.0001)\n",
      "[tensor([-0.0029,  0.9962]), tensor([ 9.9929e-01, -5.6693e-06,  6.1040e-01,  1.2337e-04])]\n",
      "127 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0027,  0.9965]), tensor([ 0.9996, -0.0000,  0.6104,  0.0001])]\n",
      "128 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0026,  0.9968]), tensor([ 0.9998, -0.0000,  0.6104,  0.0000])]\n",
      "129 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0025,  0.9971]), tensor([ 1.0000e+00,  3.8865e-07,  6.1040e-01, -2.4533e-06])]\n",
      "130 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0023,  0.9973]), tensor([ 1.0002e+00,  1.1425e-05,  6.1040e-01, -3.8450e-05])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0022,  0.9976]), tensor([ 1.0004e+00,  1.2322e-05,  6.1040e-01, -6.9384e-05])]\n",
      "132 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0021,  0.9978]), tensor([ 1.0006e+00,  3.3036e-06,  6.1040e-01, -9.4446e-05])]\n",
      "133 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0019,  0.9980]), tensor([ 1.0007e+00, -7.4916e-06,  6.1040e-01, -1.1314e-04])]\n",
      "134 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0018,  0.9982]), tensor([ 1.0008e+00, -1.1222e-05,  6.1040e-01, -1.2528e-04])]\n",
      "135 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0017,  0.9984]), tensor([ 1.0009e+00, -5.5335e-06,  6.1040e-01, -1.3097e-04])]\n",
      "136 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0016,  0.9986]), tensor([ 1.0010e+00,  4.0915e-06,  6.1041e-01, -1.3057e-04])]\n",
      "137 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0015,  0.9987]), tensor([ 1.0011e+00,  9.4589e-06,  6.1041e-01, -1.2465e-04])]\n",
      "138 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0014,  0.9989]), tensor([ 1.0012e+00,  6.5818e-06,  6.1041e-01, -1.1399e-04])]\n",
      "139 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0013,  0.9990]), tensor([ 1.0013e+00, -1.4147e-06,  6.1041e-01, -9.9471e-05])]\n",
      "140 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0012,  0.9991]), tensor([ 1.0013e+00, -7.4747e-06,  6.1041e-01, -8.2079e-05])]\n",
      "141 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0011,  0.9993]), tensor([ 1.0013e+00, -6.7731e-06,  6.1041e-01, -6.2823e-05])]\n",
      "142 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0010,  0.9994]), tensor([ 1.0014e+00, -5.2132e-07,  6.1041e-01, -4.2705e-05])]\n",
      "143 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0009,  0.9995]), tensor([ 1.0014e+00,  5.5606e-06,  6.1041e-01, -2.2674e-05])]\n",
      "144 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0008,  0.9996]), tensor([ 1.0014e+00,  6.4078e-06,  6.1041e-01, -3.5880e-06])]\n",
      "145 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0007,  0.9997]), tensor([ 1.0014e+00,  1.7982e-06,  6.1041e-01,  1.3810e-05])]\n",
      "146 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0006,  0.9997]), tensor([ 1.0014e+00, -3.8797e-06,  6.1041e-01,  2.8919e-05])]\n",
      "147 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0006,  0.9998]), tensor([ 1.0014e+00, -5.7303e-06,  6.1041e-01,  4.1291e-05])]\n",
      "148 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0005,  0.9999]), tensor([ 1.0014e+00, -2.5420e-06,  6.1041e-01,  5.0637e-05])]\n",
      "149 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0004,  0.9999]), tensor([ 1.0014e+00,  2.5015e-06,  6.1041e-01,  5.6828e-05])]\n",
      "150 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0004,  1.0000]), tensor([ 1.0013e+00,  4.9202e-06,  6.1041e-01,  5.9884e-05])]\n",
      "151 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0003,  1.0001]), tensor([ 1.0013e+00,  2.8867e-06,  6.1041e-01,  5.9962e-05])]\n",
      "152 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0003,  1.0001]), tensor([ 1.0013e+00, -1.4336e-06,  6.1041e-01,  5.7338e-05])]\n",
      "153 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0002,  1.0001]), tensor([ 1.0013e+00, -4.0978e-06,  6.1041e-01,  5.2383e-05])]\n",
      "154 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0002,  1.0002]), tensor([ 1.0012e+00, -2.9535e-06,  6.1041e-01,  4.5536e-05])]\n",
      "155 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0001,  1.0002]), tensor([ 1.0012e+00,  6.4797e-07,  6.1041e-01,  3.7284e-05])]\n",
      "156 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-0.0001,  1.0002]), tensor([ 1.0012e+00,  3.3352e-06,  6.1041e-01,  2.8133e-05])]\n",
      "157 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-6.6377e-05,  1.0003e+00]), tensor([ 1.0011e+00,  2.8421e-06,  6.1041e-01,  1.8581e-05])]\n",
      "158 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-3.4620e-05,  1.0003e+00]), tensor([ 1.0011e+00, -1.0015e-07,  6.1041e-01,  9.1029e-06])]\n",
      "159 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([-5.7622e-06,  1.0003e+00]), tensor([ 1.0010e+00, -2.6689e-06,  6.1041e-01,  1.2393e-07])]\n",
      "160 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 2.0327e-05,  1.0003e+00]), tensor([ 1.0010e+00, -2.6279e-06,  6.1041e-01, -7.9903e-06])]\n",
      "161 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 4.3782e-05,  1.0003e+00]), tensor([ 1.0010e+00, -2.5860e-07,  6.1041e-01, -1.4947e-05])]\n",
      "162 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 6.4735e-05,  1.0003e+00]), tensor([ 1.0009e+00,  2.1112e-06,  6.1041e-01, -2.0535e-05])]\n",
      "163 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 8.3319e-05,  1.0003e+00]), tensor([ 1.0009e+00,  2.3649e-06,  6.1041e-01, -2.4621e-05])]\n",
      "164 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 9.9665e-05,  1.0003e+00]), tensor([ 1.0008e+00,  4.7396e-07,  6.1041e-01, -2.7159e-05])]\n",
      "165 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0001,  1.0004]), tensor([ 1.0008e+00, -1.6598e-06,  6.1041e-01, -2.8174e-05])]\n",
      "166 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0001,  1.0004]), tensor([ 1.0008e+00, -2.0887e-06,  6.1041e-01, -2.7763e-05])]\n",
      "167 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0001,  1.0004]), tensor([ 1.0007e+00, -5.8515e-07,  6.1041e-01, -2.6079e-05])]\n",
      "168 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0001,  1.0004]), tensor([ 1.0007e+00,  1.3039e-06,  6.1041e-01, -2.3321e-05])]\n",
      "169 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0006e+00,  1.8215e-06,  6.1041e-01, -1.9721e-05])]\n",
      "170 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0006e+00,  6.2378e-07,  6.1041e-01, -1.5529e-05])]\n",
      "171 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0006e+00, -1.0296e-06,  6.1041e-01, -1.1000e-05])]\n",
      "172 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0005e+00, -1.5752e-06,  6.1041e-01, -6.3830e-06])]\n",
      "173 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0005e+00, -6.1415e-07,  6.1041e-01, -1.9065e-06])]\n",
      "174 losssssssssssssssssssss tensor(4.0000)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0005e+00,  8.2208e-07,  6.1041e-01,  2.2272e-06])]\n",
      "175 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0004e+00,  1.3553e-06,  6.1041e-01,  5.8511e-06])]\n",
      "176 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0004e+00,  5.7422e-07,  6.1041e-01,  8.8381e-06])]\n",
      "177 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0004e+00, -6.6750e-07,  6.1041e-01,  1.1103e-05])]\n",
      "178 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0003e+00, -1.1629e-06,  6.1041e-01,  1.2605e-05])]\n",
      "179 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0003e+00, -5.1677e-07,  6.1041e-01,  1.3341e-05])]\n",
      "180 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0002,  1.0003]), tensor([ 1.0003e+00,  5.5380e-07,  6.1041e-01,  1.3349e-05])]\n",
      "181 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0001,  1.0003]), tensor([ 1.0003e+00,  9.9641e-07,  6.1041e-01,  1.2696e-05])]\n",
      "182 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0001,  1.0003]), tensor([ 1.0002e+00,  4.5063e-07,  6.1041e-01,  1.1478e-05])]\n",
      "183 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0001,  1.0002]), tensor([ 1.0002e+00, -4.7085e-07,  6.1041e-01,  9.8074e-06])]\n",
      "184 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0001,  1.0002]), tensor([ 1.0002e+00, -8.5327e-07,  6.1041e-01,  7.8107e-06])]\n",
      "185 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0001,  1.0002]), tensor([ 1.0002e+00, -3.8167e-07,  6.1041e-01,  5.6178e-06])]\n",
      "186 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0001,  1.0002]), tensor([ 1.0001e+00,  4.1047e-07,  6.1041e-01,  3.3566e-06])]\n",
      "187 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0001,  1.0002]), tensor([ 1.0001e+00,  7.3024e-07,  6.1041e-01,  1.1467e-06])]\n",
      "188 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0001,  1.0002]), tensor([ 1.0001e+00,  3.1366e-07,  6.1041e-01, -9.0592e-07])]\n",
      "189 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 0.0001,  1.0002]), tensor([ 1.0001e+00, -3.6615e-07,  6.1041e-01, -2.7128e-06])]\n",
      "190 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 9.9314e-05,  1.0002e+00]), tensor([ 1.0001e+00, -6.2409e-07,  6.1041e-01, -4.2061e-06])]\n",
      "191 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 9.3302e-05,  1.0002e+00]), tensor([ 1.0001e+00, -2.4894e-07,  6.1041e-01, -5.3398e-06])]\n",
      "192 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 8.7346e-05,  1.0002e+00]), tensor([ 1.0001e+00,  3.3287e-07,  6.1041e-01, -6.0907e-06])]\n",
      "193 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 8.1470e-05,  1.0001e+00]), tensor([ 1.0000e+00,  5.3187e-07,  6.1041e-01, -6.4567e-06])]\n",
      "194 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 7.5701e-05,  1.0001e+00]), tensor([ 1.0000e+00,  1.8889e-07,  6.1041e-01, -6.4556e-06])]\n",
      "195 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 7.0059e-05,  1.0001e+00]), tensor([ 1.0000e+00, -3.0679e-07,  6.1041e-01, -6.1224e-06])]\n",
      "196 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 6.4564e-05,  1.0001e+00]), tensor([ 1.0000e+00, -4.5101e-07,  6.1041e-01, -5.5057e-06])]\n",
      "197 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 5.9232e-05,  1.0001e+00]), tensor([ 1.0000e+00, -1.3428e-07,  6.1041e-01, -4.6641e-06])]\n",
      "198 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 5.4076e-05,  1.0001e+00]), tensor([ 1.0000e+00,  2.8500e-07,  6.1041e-01, -3.6625e-06])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 losssssssssssssssssssss tensor(4.)\n",
      "[tensor([ 4.9109e-05,  1.0001e+00]), tensor([ 9.9999e-01,  3.7942e-07,  6.1041e-01, -2.5679e-06])]\n"
     ]
    }
   ],
   "source": [
    "####TRAINING\n",
    "#added params\n",
    "# core_rel = Variable(knowledge_pos[[0,1,4]])\n",
    "# target = Variable(knowledge_pos[[2,3]])\n",
    "\n",
    "core_rel = Variable(knowledge_pos)\n",
    "target = Variable(knowledge_pos)\n",
    "\n",
    "num_iters = 200\n",
    "learning_rate = .01\n",
    "drop=0\n",
    "\n",
    "steps = 1\n",
    "num_rules = 2\n",
    "epsilon=.001\n",
    "\n",
    "K = 5 ##For top K\n",
    "\n",
    "#rules should be:\n",
    "#r1(x,y) <- r1(y,x)\n",
    "#r1(x,y) <- r2(x,z),r2(z,x)\n",
    "rules = [Variable(torch.rand(num_predicates), requires_grad=True),\n",
    "         Variable(torch.rand(2*num_predicates), requires_grad=True)]\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "        {'params': rules}], \n",
    "        lr = learning_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "for epoch in range(num_iters):\n",
    "    # ##sampling\n",
    "    # core_rel = torch.randperm(no_facts)\n",
    "    # target = core_rel[no_samples:]\n",
    "    # core_rel = core_rel[:no_samples]\n",
    "\n",
    "    # core_rel = Variable(knowledge_pos[core_rel])\n",
    "    # target = Variable(knowledge_pos)\n",
    "    optimizer.zero_grad()\n",
    "    facts = torch.cat((core_rel, Variable(torch.ones(core_rel.size()[0], 1))), 1)\n",
    "    #will accumulate predictions separately to compare with target facts\n",
    "    consequences = forward_step(facts)\n",
    "    for step in range(1,steps):\n",
    "        tmp = torch.cat((consequences,facts),dim=0)\n",
    "        tmp = forward_step(tmp)\n",
    "        consequences = torch.cat((consequences,tmp),dim=0)\n",
    "\n",
    "    loss = 0\n",
    "    for targ in target:\n",
    "        _, indi = torch.max(F.cosine_similarity(targ.view(1,-1).expand(consequences[:,:-1].size()),consequences[:,:-1]),0)\n",
    "        indi=indi.data[0]\n",
    "        loss += criterion(consequences[indi,:-1],targ)+(1-(consequences[indi,-1]))\n",
    "        #remove fact from predicted facts\n",
    "        # if indi==0:\n",
    "        #     facts = facts[1:,:]\n",
    "        # elif indi+1 == facts.size()[0]:\n",
    "        #     facts = facts[:indi,:]\n",
    "        # else:\n",
    "        #     facts = torch.cat((facts[:indi,:],facts[indi+1:,:]),dim=0)\n",
    "\n",
    "    print(epoch, 'losssssssssssssssssssss',loss.data[0])\n",
    "    print(rules)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7627,  0.1373,  0.8353,  0.3743],\n",
       "        [ 0.7627,  0.1373,  0.8353,  0.3743]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
