{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'locatedIn', 1: 'neighborOf'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from pudb import set_trace;\n",
    "import time\n",
    "\n",
    "with open('data/countries_s1') as f:\n",
    "    facts = f.read().splitlines()\n",
    "facts = [el.split(',') for el in facts]\n",
    "preds = [fact[0] for fact in facts]\n",
    "subjs = [fact[1] for fact in facts]\n",
    "objs = [fact[2] for fact in facts]\n",
    "\n",
    "unique = sorted(list(set(preds)))\n",
    "num_unique = len(unique)\n",
    "num_predicates = num_unique\n",
    "predsToIdx = dict(zip(unique,range(num_unique)))\n",
    "idxToPreds = dict(zip(range(num_unique),unique))\n",
    "print(idxToPreds)\n",
    "\n",
    "unique = sorted(list(set(subjs+objs)))\n",
    "num_unique = len(unique)\n",
    "num_constants = num_unique\n",
    "consToIdx = dict(zip(unique,range(num_unique)))\n",
    "idxToCons = dict(zip(range(num_unique),unique))\n",
    "\n",
    "facts = np.array([(predsToIdx[preds[i]],consToIdx[subjs[i]], consToIdx[objs[i]]) for i in range(len(facts))])\n",
    "data = np.zeros((num_predicates,num_constants,num_constants))\n",
    "\n",
    "#data: idx0->predicate, idx1->subj, idx2->obj\n",
    "data[facts[:,0],facts[:,1],facts[:,2]] = 1\n",
    "no_facts = int(np.sum(data))\n",
    "data = torch.from_numpy(data)\n",
    "\n",
    "predicates = torch.eye(num_predicates)\n",
    "constants = torch.eye(num_constants)\n",
    "\n",
    "knowledge_pos = (data==1).nonzero()\n",
    "data_aux = knowledge_pos\n",
    "knowledge_pos = torch.cat((predicates[knowledge_pos[:,0]],\n",
    "                           constants[knowledge_pos[:,1]],\n",
    "                           constants[knowledge_pos[:,2]]),dim=1)\n",
    "\n",
    "num_feats_per_fact = knowledge_pos.size()[1]\n",
    "\n",
    "#reading the test set\n",
    "with open('data/s1_test') as f:\n",
    "    test = f.read().splitlines()\n",
    "test = [el.split(',') for el in test]\n",
    "preds = [fact[0] for fact in test]\n",
    "subjs = [fact[1] for fact in test]\n",
    "objs = [fact[2] for fact in test]\n",
    "\n",
    "test = np.array([(predsToIdx[preds[i]],consToIdx[subjs[i]], consToIdx[objs[i]]) for i in range(len(test))])\n",
    "ts_data = np.zeros((num_predicates,num_constants,num_constants))\n",
    "ts_data[test[:,0],test[:,1],test[:,2]] = 1\n",
    "ts_data = torch.from_numpy(ts_data)\n",
    "test = (ts_data==1).nonzero()\n",
    "test = torch.cat((predicates[test[:,0]],\n",
    "                   constants[test[:,1]],\n",
    "                   constants[test[:,2]]),dim=1)\n",
    "\n",
    "#sample num_samples as a connected subgraph of the input data\n",
    "#   basically, perform num_samples steps, each adding one more fact\n",
    "#   that is connected to at least one constant in the sample\n",
    "#data: a tensor of the form num_preds,num_cons,num_cons where a 1\n",
    "#   means that the fact composed of pred,cons1,cons2 is true\n",
    "#num_samples: number of samples to be gotten\n",
    "#returns sample: a tensor of the form num_samples*num_feats_per_fact\n",
    "def sample_neighbors(num_samples,data):\n",
    "    data_source_tmp = data.clone()\n",
    "    data_tmp = torch.zeros_like(data)\n",
    "    sample = torch.zeros(0,num_feats_per_fact,dtype=torch.long)\n",
    "    #choose one random constant\n",
    "    idx = torch.randperm(num_constants)[0].unsqueeze(0)\n",
    "    for _ in range(num_samples):\n",
    "    #     print('data_source',data_source_tmp)\n",
    "        #subset your possible choices to where idx is subject or object\n",
    "        data_tmp[:,idx,:] = data_source_tmp[:,idx,:]\n",
    "        data_tmp[:,:,idx] = data_source_tmp[:,:,idx]\n",
    "        #choose one at random\n",
    "        new_fact = data_tmp.nonzero()\n",
    "        if new_fact.size()[0] == 0:\n",
    "            break\n",
    "        chosen = torch.randperm(new_fact.size()[0])[0]\n",
    "        new_fact = new_fact[chosen,:].unsqueeze(0)\n",
    "        #add fact to sample\n",
    "        sample = torch.cat((sample,new_fact),dim=0)\n",
    "        #set chosen fact to zero (avoiding choosing it again)\n",
    "        data_source_tmp[new_fact[:,0],new_fact[:,1],new_fact[:,2]] = 0\n",
    "        #add new idx in the fact\n",
    "        idx = torch.cat((idx,new_fact[:,1],new_fact[:,2]))\n",
    "        idx = torch.unique(idx)\n",
    "    sample = torch.cat((predicates[sample[:,0]],\n",
    "                        constants[sample[:,1]],\n",
    "                        constants[sample[:,2]]),dim=1)\n",
    "    return sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#helps removing repeated predicted facts -> same embeddings and constants, probably different scores\n",
    "#this is of complexity K^3, could be optimized\n",
    "def leaveTopK(preds,K):\n",
    "    _,idx = torch.sort(preds[:,-1],descending=True)\n",
    "    preds = preds[idx,:]\n",
    "    out = preds[0,:].unsqueeze(0)\n",
    "    for i in range(1,min(K,preds.size()[0])):\n",
    "        t = preds[i,:].unsqueeze(0)\n",
    "        if t[:,-1] == 0:\n",
    "            break\n",
    "        m,_ = torch.max(F.cosine_similarity(t[:,:-1].repeat(out.size()[0],1),out[:,:-1],dim=1),dim=0)\n",
    "        if m<1:\n",
    "            out = torch.cat((out,t),dim=0)\n",
    "    return out\n",
    "\n",
    "####FORWARD CHAINING\n",
    "#input: some facts that can either be ground or predicted in previous steps\n",
    "#output: predicted facts in this specific step (outer loop must gather all of them)\n",
    "#computes the predictions of applying each rule to the facts, giving a score to each of them.\n",
    "#leaves only topK scoring fact for each applied rule (not for the whole thing)\n",
    "def forward_step(facts,K):\n",
    "    num_facts = facts.size()[0]\n",
    "    #rule 1\n",
    "    # b1(x,y)<-b2(y,x)\n",
    "    start_time = time.time()\n",
    "    rule_expanded = rules[0].repeat(num_facts,1)\n",
    "    preds_r1 = F.cosine_similarity(rule_expanded[:,num_predicates:],facts[:,:num_predicates],dim=1)\n",
    "    preds_r1 = preds_r1*facts[:,-1]\n",
    "    preds_r1 = preds_r1.unsqueeze(1)\n",
    "    preds_r1 = torch.cat((rule_expanded[:,:num_predicates],\n",
    "                         facts[:,num_predicates+num_constants:-1],\n",
    "                         facts[:,num_predicates:num_predicates+num_constants],\n",
    "                         preds_r1),dim=1)\n",
    "    # print(preds_r1)\n",
    "    preds_r1 = leaveTopK(preds_r1,K)\n",
    "    \n",
    "    #rule 2\n",
    "    #b1(x,y)<-b2(x,z),b3(z,y)\n",
    "    body1 = facts.repeat((1,num_facts)).view(-1,num_feats_per_fact+1)\n",
    "    body2 = facts.repeat((num_facts,1))\n",
    "    rule_expanded = rules[1].repeat(body1.size()[0],1)\n",
    "    #previous scores\n",
    "    preds_r2 = body1[:,-1]*body2[:,-1]\n",
    "    #similarity between shared constants\n",
    "    preds_r2 = preds_r2*F.cosine_similarity(body1[:,num_predicates+num_constants:-1],\n",
    "                                            body2[:,num_predicates:num_predicates+num_constants],dim=1)\n",
    "    #remove 0 scores to improve speed - if constant isn't shared we don't compute anything else\n",
    "    non_zero = preds_r2.nonzero().squeeze()\n",
    "    preds_r2 = preds_r2[non_zero]\n",
    "    rule_expanded = rule_expanded[non_zero,:]\n",
    "    body1 = body1[non_zero,:]\n",
    "    body2 = body2[non_zero,:]\n",
    "    \n",
    "    #predicate of body1 with predicate of rule\n",
    "    preds_r2 = preds_r2*F.cosine_similarity(rule_expanded[:,num_predicates:2*num_predicates],body1[:,:num_predicates],dim=1)\n",
    "    #predicate of body2 with predicate of rule\n",
    "    preds_r2 = preds_r2*F.cosine_similarity(rule_expanded[:,2*num_predicates:],body2[:,:num_predicates],dim=1)\n",
    "    \n",
    "    preds_r2 = preds_r2.unsqueeze(1)\n",
    "    preds_r2 = torch.cat((rule_expanded[:,:num_predicates]\n",
    "                         ,body1[:,num_predicates:num_predicates+num_constants]\n",
    "                         ,body2[:,num_predicates+num_constants:-1]\n",
    "                         ,preds_r2)\n",
    "                        ,dim=1)\n",
    "    #removing repeated facts and leaving ones with highest score\n",
    "    preds_r2 = leaveTopK(preds_r2,K)\n",
    "    out = torch.cat((preds_r1,preds_r2),dim=0)\n",
    "    print(\"fws took %s\" % (time.time() - start_time))\n",
    "    return out\n",
    "    # return preds_r2\n",
    "\n",
    "    \n",
    "####TRAINING\n",
    "#dbg -> cherrypicked\n",
    "# core_rel = Variable(knowledge_pos[[0,1,3]])\n",
    "# target = Variable(knowledge_pos[2]).unsqueeze(0)\n",
    "# target = Variable(knowledge_pos[[2,4],:])\n",
    "#####sampling\n",
    "target = Variable(knowledge_pos)\n",
    "no_samples = 50\n",
    "\n",
    "num_iters = 100\n",
    "learning_rate = .1\n",
    "lamb = 1\n",
    "\n",
    "steps = 2\n",
    "num_rules = 2\n",
    "epsilon=.001\n",
    "\n",
    "K = 30 ##For top K\n",
    "#Find maximum similarity for each consequence in the set of facts contained in target\n",
    "#if testing is true it finds the consequence with maximum similarity for each target\n",
    "#if testing is true, returns the truth value of the matched predicted consequence for each target\n",
    "#Inputs: \n",
    "#consequences: facts to be looked for maximum similarities across target\n",
    "#target: set of facts that are assumed to be true\n",
    "#testing: returns the probabilities of matched facts, a prediction is considered true if p>0.5\n",
    "def find_max_similarities(consequences,target,testing=False):\n",
    "    start_time = time.time()    \n",
    "    num_consequences = consequences.size()[0]\n",
    "    num_targets = target.size()[0]\n",
    "\n",
    "    #each consequence repeated by the number of targets\n",
    "    if testing:\n",
    "        #for each target find max similarity across consequences\n",
    "        tmp_c = consequences.repeat(num_targets,1)\n",
    "        tmp_t = target.repeat(1,num_consequences).view(-1,num_feats_per_fact)\n",
    "    else:\n",
    "        #for each consequence compute the similarity with all targets\n",
    "        tmp_c = consequences.repeat(1,num_targets).view(-1,num_feats_per_fact+1)\n",
    "        tmp_t = target.repeat(num_consequences,1)\n",
    "\n",
    "    sim = F.cosine_similarity(tmp_c[:,num_predicates:num_predicates+num_constants],\n",
    "                              tmp_t[:,num_predicates:num_predicates+num_constants],dim=1)\n",
    "    #only compute for non-zero values to speed up\n",
    "    non_zero = sim.nonzero().squeeze()\n",
    "\n",
    "    sim[non_zero] = sim[non_zero] * F.cosine_similarity(tmp_c[non_zero,num_predicates+num_constants:-1],\n",
    "                                                        tmp_t[non_zero,num_predicates+num_constants:],dim=1)\n",
    "\n",
    "    non_zero = sim.nonzero().squeeze()\n",
    "\n",
    "    sim[non_zero] = sim[non_zero] * F.cosine_similarity(tmp_c[non_zero,:num_predicates]\n",
    "                                                       ,tmp_t[non_zero,:num_predicates],dim=1)\n",
    "    \n",
    "    #for each consequence/target, get the maximum simlarity with the set of targets/consequences\n",
    "    if testing:\n",
    "        sim = sim.view(-1,num_consequences)\n",
    "    else:\n",
    "        sim = sim.view(-1,num_targets)\n",
    "    m, idx = torch.max(sim,dim=1)\n",
    "    print(\"fms took %s\" % (time.time() - start_time))\n",
    "    if testing:\n",
    "        return m, tmp_c[idx,-1]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fws took 0.02703690528869629\n",
      "fws took 0.08900976181030273\n",
      "fms took 0.760657787322998\n",
      "0 losssssssssssssssssssss tensor(10.3896)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aldo.pareja/miniconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 7.4506e-09,  1.0000e+00,  1.4901e-08,  1.0000e+00]), tensor([ 2.0000e-01,  8.0002e-01,  1.0000e+00,  7.4506e-09,  1.4901e-08,\n",
      "         1.0000e+00])]\n",
      "fws took 0.018731117248535156\n",
      "fws took 0.04936504364013672\n",
      "fms took 0.8886420726776123\n",
      "1 losssssssssssssssssssss tensor(11.4990)\n",
      "[tensor([ 0.0001,  0.9999,  0.0060,  0.9940]), tensor([ 1.4346e-01,  8.6683e-01,  1.0000e+00, -6.9886e-06,  3.1210e-02,\n",
      "         9.6879e-01])]\n",
      "fws took 0.02013707160949707\n",
      "fws took 0.05693793296813965\n",
      "fms took 0.7201879024505615\n",
      "2 losssssssssssssssssssss tensor(9.7532)\n",
      "[tensor([ 0.0001,  0.9999,  0.0042,  0.9958]), tensor([ 0.0752,  0.9368,  0.9994,  0.0006,  0.0432,  0.9568])]\n",
      "fws took 0.021111249923706055\n",
      "fws took 0.04829525947570801\n",
      "fms took 0.9696073532104492\n",
      "3 losssssssssssssssssssss tensor(10.4479)\n",
      "[tensor([-3.6202e-05,  1.0000e+00,  2.6676e-03,  9.9733e-01]), tensor([ 0.0754,  0.9423,  0.9995,  0.0005,  0.0275,  0.9725])]\n",
      "fws took 0.02122783660888672\n",
      "fws took 0.06456804275512695\n",
      "fms took 0.7914056777954102\n",
      "4 losssssssssssssssssssss tensor(9.6068)\n",
      "computing test results\n",
      "fws took 10.195479154586792\n",
      "fws took 34.318053245544434\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cc52f0b0b72c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mconsequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_max_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-52047c74df43>\u001b[0m in \u001b[0;36mfind_max_similarities\u001b[0;34m(consequences, target, testing)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     sim[non_zero] = sim[non_zero] * F.cosine_similarity(tmp_c[non_zero,:num_predicates]\n\u001b[0;32m--> 226\u001b[0;31m                                                        ,tmp_t[non_zero,:num_predicates],dim=1)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m#for each consequence/target, get the maximum simlarity with the set of targets/consequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(x1, x2, dim, eps)\u001b[0m\n\u001b[1;32m   1985\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m     \"\"\"\n\u001b[0;32m-> 1987\u001b[0;31m     \u001b[0mw12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1988\u001b[0m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m     \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "K_tmp = K\n",
    "#rules should be:\n",
    "#r1(x,y) <- r2(y,x)\n",
    "#r1(x,y) <- r2(x,z),r3(z,x)\n",
    "rules = [Variable(torch.Tensor([ 0.1000,  0.9000,  0.1000,  0.9000]), requires_grad=True),\n",
    "         Variable(torch.Tensor([ 0.1000,  0.9000,  0.9000,  0.1000,  0.1000,  0.9000]), requires_grad=True)]\n",
    "# rules = [Variable(torch.rand(num_predicates), requires_grad=True),\n",
    "#          Variable(torch.Tensor([1, 1]), requires_grad=True)]\n",
    "optimizer = torch.optim.Adam([\n",
    "        {'params': rules}], \n",
    "        lr = learning_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "rules_tmp = [torch.zeros_like(rule) for rule in rules]\n",
    "for epoch in range(num_iters):\n",
    "    for par in optimizer.param_groups:\n",
    "        par['params'][1].data.clamp_(min=0.1,max=0.9)\n",
    "        par['params'][0].data.clamp_(min=0.1,max=0.9)\n",
    "    # ##sampling\n",
    "    core_rel = torch.randperm(no_facts)\n",
    "    # # target = core_rel[no_samples:]\n",
    "    core_rel = core_rel[:no_samples]\n",
    "\n",
    "    # core_rel = Variable(knowledge_pos[core_rel])\n",
    "    core_rel = sample_neighbors(no_samples,data)\n",
    "    # target = Variable(knowledge_pos)\n",
    "    optimizer.zero_grad()\n",
    "    facts = torch.cat((core_rel, Variable(torch.ones(core_rel.size()[0], 1))), 1)\n",
    "    #will accumulate predictions separately to compare with target facts\n",
    "    consequences = forward_step(facts,K_tmp)\n",
    "    for step in range(1,steps):\n",
    "        tmp = torch.cat((consequences,facts),dim=0)\n",
    "        tmp = forward_step(tmp,K_tmp)\n",
    "        consequences = torch.cat((consequences,tmp),dim=0)\n",
    "    #LOSS\n",
    "    loss = 0\n",
    "    m = find_max_similarities(consequences,target)\n",
    "    loss = torch.sum(lamb*consequences[:,-1]*(1 - consequences[:,-1]*m))\n",
    "    print(epoch, 'losssssssssssssssssssss',loss.data[0])\n",
    "    # print(sum([torch.sum(rules_tmp[i]-rules[i]) for i in range(num_rules)]))\n",
    "    if loss < 10**-6 or sum([torch.sum(torch.abs(rules_tmp[i]-rules[i])) for i in range(num_rules)])<10**-5:\n",
    "        break\n",
    "    rules_tmp = [r.clone() for r in rules]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(rules)\n",
    "\n",
    "\n",
    "#computing test results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    76,    229,    540,   1108,   1182,   1316,   1604,   1687,\n",
      "          1776,   2449,   2450,   2735,   2761,   3412,   4049,   4154,\n",
      "          4157,   4158,   4159,   4161,   4362,   4461,   4975,   5609,\n",
      "          5711,   6030,   6238,   6403,   6412,   6421,   6429,   6436,\n",
      "          6437,   6484,   6830,   7247,   7702,   7786,   7790,   7872,\n",
      "          7912,   8200,   8304,   8364,   8401,   8404,   8657,   8661,\n",
      "          8666,   8668,   8745,   9307,   9516,  10099,  10538,  10987,\n",
      "         12003,  12011,  12097,  12283,  12582,  12604,  12648,  13088,\n",
      "         13095,  13367,  13706,  13733,  14392,  14595,  14596,  14604,\n",
      "         14605,  14606,  14607,  14608,  14623,  14745,  15524,  15538,\n",
      "         15759,  15760,  15761,  15762,  15763,  15764,  15826,  16283,\n",
      "         16293,  16307,  16356,  16369,  16456,  16940,  16963,  17001,\n",
      "         17661,  17671,  17974,  17982,  18158,  18612,  18732,  18776,\n",
      "         18795,  18803,  19081,  19097,  19106,  19336,  19342,  19370,\n",
      "         19376,  19384,  19392,  19609,  19718,  19725,  19804,  19873,\n",
      "         20178,  20240,  20420,  20804,  20842,  20892,  21458,  21834,\n",
      "         22462,  23071,  24020,  24126,  24626,  24764,  24784,  24882,\n",
      "         24883,  24884,  24885,  24893,  25762]) 2 torch.Size([26160, 545]) torch.Size([26160, 544])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ce54093a27a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     tmp = forward_step(tmp,K_tmp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     consequences = torch.cat((consequences,tmp),dim=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_max_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-ac19472f58a3>\u001b[0m in \u001b[0;36mfind_max_similarities\u001b[0;34m(consequences, target, testing)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     sim[non_zero] = sim[non_zero] * F.cosine_similarity(tmp_c[non_zero,:num_predicates]\n\u001b[0;32m---> 28\u001b[0;31m                                                        ,tmp_t[non_zero,:num_predicates],dim=1)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#for each consequence/target, get the maximum simlarity with the set of targets/consequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(x1, x2, dim, eps)\u001b[0m\n\u001b[1;32m   1985\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m     \"\"\"\n\u001b[0;32m-> 1987\u001b[0;31m     \u001b[0mw12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1988\u001b[0m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m     \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_similarities(consequences,target,testing=False):\n",
    "    start_time = time.time()    \n",
    "    num_consequences = consequences.size()[0]\n",
    "    num_targets = target.size()[0]\n",
    "\n",
    "    #each consequence repeated by the number of targets\n",
    "    if testing:\n",
    "        #for each target find max similarity across consequences\n",
    "        tmp_c = consequences.repeat(num_targets,1)\n",
    "        tmp_t = target.repeat(1,num_consequences).view(-1,num_feats_per_fact)\n",
    "    else:\n",
    "        #for each consequence compute the similarity with all targets\n",
    "        tmp_c = consequences.repeat(1,num_targets).view(-1,num_feats_per_fact+1)\n",
    "        tmp_t = target.repeat(num_consequences,1)\n",
    "\n",
    "    sim = F.cosine_similarity(tmp_c[:,num_predicates:num_predicates+num_constants],\n",
    "                              tmp_t[:,num_predicates:num_predicates+num_constants],dim=1)\n",
    "    #only compute for non-zero values to speed up\n",
    "    non_zero = sim.nonzero().squeeze()\n",
    "    if non_zero.size()[0]==0:\n",
    "        sim = torch.zeros_like(sim)\n",
    "    else:\n",
    "        sim[non_zero] = sim[non_zero] * F.cosine_similarity(tmp_c[non_zero,num_predicates+num_constants:-1],tmp_t[non_zero,num_predicates+num_constants:],dim=1)\n",
    "\n",
    "    non_zero = sim.nonzero().squeeze()\n",
    "    if non_zero.size()[0]==0:\n",
    "        sim = torch.zeros_like(sim)\n",
    "    else:\n",
    "        sim[non_zero] = sim[non_zero] * F.cosine_similarity(tmp_c[non_zero,:num_predicates] ,tmp_t[non_zero,:num_predicates],dim=1)\n",
    "    \n",
    "    #for each consequence/target, get the maximum simlarity with the set of targets/consequences\n",
    "    if testing:\n",
    "        sim = sim.view(-1,num_consequences)\n",
    "    else:\n",
    "        sim = sim.view(-1,num_targets)\n",
    "    m, idx = torch.max(sim,dim=1)\n",
    "    print(\"fms took %s\" % (time.time() - start_time))\n",
    "    if testing:\n",
    "        return m, tmp_c[idx,-1]\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fms took 0.2037050724029541\n",
      "ts_accuracy 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print('computing test results')\n",
    "# K_tmp = 400\n",
    "# facts = torch.cat((knowledge_pos, Variable(torch.ones(knowledge_pos.size()[0], 1))), 1)\n",
    "# consequences = forward_step(facts,K_tmp)\n",
    "# for step in range(1,steps):\n",
    "#     tmp = torch.cat((consequences,facts),dim=0)\n",
    "#     tmp = forward_step(tmp,K_tmp)\n",
    "#     consequences = torch.cat((consequences,tmp),dim=0)\n",
    "m,p = find_max_similarities(consequences,test,testing=True)\n",
    "true_positives = m[p>0.5]\n",
    "true_positives = (true_positives>0.5).nonzero()\n",
    "true_positives = true_positives.size()[0]\n",
    "ts_accuracy = true_positives/test.size()[0]\n",
    "print('ts_accuracy '+str(ts_accuracy)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1462, 545])\n"
     ]
    }
   ],
   "source": [
    "print(consequences.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
